---
title: "test workflow"
author: "Barnaby Walker"
date: '2022-07-25'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I'm running through the rWCVP package functions to test them out in what might be a semi-realistic workflow that spans all of the functions (hopefully) to test them out.

The task that I'll be trying to do is build a checklist of species in Brazil, and then find the species within that checklist that have an assessment listed on the IUCN Red List.

The steps I'll take to do this are:

1. Get a checklist of accepted species that occur within Brazil from the WCVP
2. Match a download of IUCN assessments to accepted species in the WCVP

The packages I'll be using to do that are:

* `rWCVP` to build checklists, get distributions, and match names to accepted species in the WCVP
* `rWCVPData`, an unreleased package that loads the latest WCVP tables
* `tidyverse`, a collection of packages for manipulating and plotting data
* `scico`, which provides scientific colormaps from [Fabio Crameri](https://www.fabiocrameri.ch/colourmaps/)
* `glue` for nice string formatting
* `tictoc` to time how long some things take

```{r packages, warning=FALSE, message=FALSE}
library(rWCVP)
library(rWCVPdata)
library(tidyverse)
library(scico)
library(glue)
library(tictoc)
```

## Getting set up

To speed things up, we'll load the WCVP name and distribution tables here. These should be accepted by all of the functions in the rWCVP package.

```{r load-wcvp}
wcvp_names <- rWCVPdata::wcvp_names
wcvp_distributions <- rWCVPdata::wcvp_distributions
```

Another thing we can do is define the geography we want. WCVP used WGSRPD level 3 but normal countries or regions of span more than one of these. rWCVP provides a function to return all the WGSRPD level 3 regions for a particular country/region, and this can be used as input to the checklist and distribution functions.

```{r define-area}
brazil <- get_wgsrpd3_codes("Brazil")
```

## Getting a checklist of Brazilian plants

As a start, to get an idea of how big the flora is, we'll use the `summary_table` function to give a summary of the species in Brazil.

```{r brazil-summary}
summary <-
  summary_table(
  area=brazil,
  grouping.var="family",
  wcvp_names=wcvp_names,
  wcvp_distributions=wcvp_distributions
)

summary
```

This can also be printed as a prettier table.

```{r pretty-summary}
summary_table_gt(summary)
```

Now we can make the actual checklist using the `generate_checklist` function. 

This has lots of arguments to refine the checklist, so it gives you exactly what you want. We'll set these to only return native records (not introduced, extinct, or doubtful) for taxa. We'll also tell it not to return synonyms because I find them uninteresting.

You can also generate a checklist for a particular taxonomic group or area, or both. We just want all species in Brazil, using the WGSRPD level 3 regions we defined earlier.

```{r brazil-checklist, warning=FALSE, message=FALSE}
checklist <- generate_checklist(
  area=brazil, 
  native=TRUE,
  introduced=FALSE,
  extinct=FALSE,
  location_doubtful=FALSE,
  synonyms=FALSE
)

count(checklist, taxon_rank)
```

Just checking what we get back, which is everything from species down.

One thing I found confusing was the 'rank' kwarg - I thought it meant 'return everything of this rank' rather than 'the taxon i am inputting is of this rank'. Is there some way of making this clearer? It might just be because I didn't read the docs properly. Or there might need to be a bit of explanation about what a checklist is in the documentation.

Generate checklist also gives us the option of returning a report, which I'll try out now.

```{r brazil-checklist-report}
checklist <- generate_checklist(
  area=brazil, 
  native=TRUE,
  introduced=FALSE,
  extinct=FALSE,
  location_doubtful=FALSE,
  synonyms=FALSE,
  render.report=TRUE,
  report.dir=here::here()
)
```

This is too much memory. Works for the example in the docs though but takes a loooooong time.

Is there some way we could make this render faster/with less memory requirement?

The final checklisting function let's us make an occurrence matrix, `generate_occurrence_matrix()`.

```{r occ-mat}
occ_mat <- generate_occurrence_matrix(
  area=brazil, 
  native=TRUE,
  introduced=FALSE,
  extinct=FALSE,
  location_doubtful=FALSE,
  wcvp_names=wcvp_names,
  wcvp_distributions=wcvp_distributions
)
```

Then we could have a go at making some sort of plot from this.
```{r}
wgsrpd <- rWCVPdata::wgsprd3

occ_richness <-
  occ_mat %>%
  pivot_longer(
    cols=c(-plant_name_id, -taxon_name), 
    names_to="area_code_l3",
    values_to="present"
  ) %>%
  group_by(area_code_l3) %>%
  summarise(species=sum(present), .groups="drop")

wgsrpd %>%
  filter(LEVEL1_COD == 8) %>%
  left_join(occ_richness, by=c("LEVEL3_COD"="area_code_l3")) %>%
  ggplot(mapping=aes(fill=species)) +
  geom_sf(color="white") +
  scale_fill_scico(palette="batlowK", na.value="grey80") +
  theme(
    panel.background=element_blank()
  )
```

## Match IUCN assessments to checklist names

```{r load-iucn}
assessments <- read_csv(here::here("redlist_plants_2021_3/simple_summary.csv"),
                        show_col_types=FALSE)
assessments <- filter(assessments, phylumName == "TRACHEOPHYTA")
glue("{length(unique(assessments$scientificName))} names to match")
```

```{r match-names}
matched <- match_names(
  assessments,
  name_col="scientificName",
  id_col="internalTaxonId",
  author_col="authority",
  wcvp_names=wcvp_names
)
```

God this takes forever - 23 min for 961 names, why?? Is there an error? it shouldn't be this bad...

Which part takes so long?

Exact matching with author?

```{r time-exact-match}
print(nrow(assessments))

tic()
exact_author <- exact_match(
  assessments,
  name_col="scientificName",
  author_col="authority",
  id_col="internalTaxonId",
  wcvp_names=wcvp_names
)
toc()
```

No.

Exact matching without author?

```{r time-exact-match}
author_matches <- filter(exact_author, !is.na(match_type))
unmatched <- filter(assessments, ! internalTaxonId %in% author_matches$internalTaxonId)
print(nrow(unmatched))

tic()
exact <- exact_match(
  unmatched,
  name_col="scientificName",
  author_col=NULL,
  id_col="internalTaxonId",
  wcvp_names=wcvp_names
)
toc()
```

No.

Phonetic matching?

```{r time-phonetic-match}
exact_matches <- filter(exact, !is.na(match_type))
unmatched <- filter(unmatched, ! internalTaxonId %in% exact_matches$internalTaxonId)
print(nrow(unmatched))

tic()
phonetic <- phonetic_match(
  unmatched,
  name_col="scientificName",
  wcvp_names=wcvp_names
)
toc()
```

No.

Edit distance matching?

```{r time-phonetic-match}
phonetic_matches <- filter(phonetic, !is.na(match_type))
unmatched <- filter(unmatched, ! internalTaxonId %in% phonetic_matches$internalTaxonId)
print(nrow(unmatched))

tic()
edit <- edit_match(
  unmatched,
  name_col="scientificName",
  wcvp_names=wcvp_names
)
toc()
```

An hour?????????????????? Why is this so slow?

We can see in the report earlier that we've got some multiple matches. Because we're matching to assessments, we'll only keep matches to names that are accepted or homotypic synonyms - we can't be sure the concept is the same otherwise. We're also going to be quite strict on matching, limiting it to things with a similarity over 0.95 and less than 4 edits. If multiple matches exist after that, we'll take accepted names and throw away anything the remains with more than one match.

```{r resolve-matches}
resolved <- 
  matched %>%
  filter(wcvp_status == "Accepted" | (wcvp_status == "Synonym" & !is.na(wcvp_homotypic))) %>%
  filter(match_edit_distance < 4, match_similarity > 0.95) %>%
  group_by(internalTaxonId) %>%
  mutate(multiple_matches=n() > 1) %>%
  filter(!multiple_matches | (wcvp_status == "Accepted")) %>%
  ungroup() %>%
  group_by(internalTaxonId) %>%
  mutate(multiple_matches=n() > 1) %>%
  ungroup() %>%
  filter(!multiple_matches)
  
```

Now we can link the IUCN assessments to accepted names in WCVP. There are some assessments matched to the same accepted species - we'll assume the ones that have the same name as the accepted species are the latest.

```{r link-assessments}
wcvp_assessments <-
  resolved %>%
  select(wcvp_id, scientificName, wcvp_name, wcvp_accepted_id, assessmentId,
         criteriaVersion, redlistCategory, redlistCriteria, match_type, wcvp_status) %>%
  filter(criteriaVersion == 3.1) %>%
  group_by(wcvp_accepted_id) %>%
  filter(n() == 1 | wcvp_status == "Accepted") %>%
  filter(row_number() == 1) %>%
  ungroup() %>%
  select(wcvp_accepted_id, redlistCategory, redlistCriteria)


occ_ass <-
  occ_mat %>%
  left_join(
    wcvp_assessments,
    by=c("plant_name_id"="wcvp_accepted_id")
  )

sum(!is.na(occ_ass$redlistCategory))
length(unique(occ_ass$plant_name_id))
```

We can see what the distribution of statuses in our occurrence matrix is.

```{r}
cat_order <- c("Unevaluated", "Data Deficient", "Least Concern",
               "Near Threatened", "Vulnerable", "Endangered", 
               "Critically Endangered", "Extinct in the Wild")
occ_ass %>%
  replace_na(list(redlistCategory="Unevaluated")) %>%
  mutate(redlistCategory=factor(redlistCategory, cat_order, ordered=TRUE)) %>%
  count(redlistCategory) %>%
  ggplot(mapping=aes(y=redlistCategory, x=n, fill=redlistCategory)) +
  geom_col() +
  geom_text(mapping=aes(label=n), hjust=0) +
  labs(x="Species", y="") +
  scale_fill_scico_d(palette="lajolla") +
  scale_x_continuous(expand=expand_scale(mult=c(0, 0.2)))
  theme(legend.position="bottom")
```

And plot a map of coverage of assessments.

```{r plot-assessments}
ass_coverage <-
  occ_ass %>%
  mutate(redlistCategory=ifelse(!redlistCategory %in% cat_order[3:7], NA_character_, redlistCategory)) %>%
  mutate(redlistCategory=factor(redlistCategory, cat_order[3:7], ordered=TRUE)) %>%
  pivot_longer(
    cols=c(-plant_name_id, -taxon_name, -redlistCategory, -redlistCriteria), 
    names_to="area_code_l3",
    values_to="present"
  ) %>%
  group_by(area_code_l3) %>%
  summarise(
    species=sum(present), 
    assessed=sum(present & !is.na(redlistCategory)) / sum(present),
    threatened=sum(present & (redlistCategory > "Near Threatened"), na.rm=T) / sum(present & !is.na(redlistCategory)),
    .groups="drop")

wgsrpd %>%
  filter(LEVEL1_COD == 8) %>%
  left_join(ass_coverage, by=c("LEVEL3_COD"="area_code_l3")) %>%
  ggplot(mapping=aes(fill=assessed)) +
  geom_sf(color="white") +
  scale_fill_scico(palette="oslo", na.value="grey80", limits=c(0, 1), direction=-1) +
  theme(
    panel.background=element_blank()
  )
```

And threatened species.


```{r plot-threatened}
wgsrpd %>%
  filter(LEVEL1_COD == 8) %>%
  left_join(ass_coverage, by=c("LEVEL3_COD"="area_code_l3")) %>%
  ggplot(mapping=aes(fill=threatened)) +
  geom_sf(color="white") +
  scale_fill_scico(palette="lajolla", na.value="grey80", limits=c(0, 1)) +
  theme(
    panel.background=element_blank()
  )
```


